import asyncio
import websockets
import tempfile
import json
import numpy as np
import soundfile as sf
from dotenv import load_dotenv
from google.cloud import speech
from fastapi import WebSocket
from langchain_community.chat_models import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

load_dotenv()

SAMPLE_RATE = 48000
SILENCE_THRESHOLD = 100
SILENCE_FRAMES = 3
BUFFER_SECONDS = 5
BUFFER_SIZE = SAMPLE_RATE * BUFFER_SECONDS

client = speech.SpeechClient()
config = speech.RecognitionConfig(
    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
    sample_rate_hertz=SAMPLE_RATE,
    language_code="ko-KR"
)

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2)

def extract_action_and_message(text: str):
    action = "WAIT"
    message = text.strip()
    if "í–‰ë™:" in text:
        parts = text.split("í–‰ë™:")
        message = parts[0].strip()
        action_line = parts[1].strip().splitlines()[0]
        if "[" in action_line and "]" in action_line:
            extracted = action_line.split("]")[0][1:].strip().upper()
            if extracted in {"NEXT", "REPLAY", "WAIT"}:
                action = extracted
    if message.lower().startswith("ë©”ì‹œì§€:"):
        message = message[len("ë©”ì‹œì§€:"):].strip(" '\"\n")
    return action, message


async def transcribe_and_respond(websocket: WebSocket):
    await websocket.accept()
    print("âœ… WebSocket ì—°ê²° ìˆ˜ë½ë¨")

    try:
        # ì´ˆê¸° ë©”ì‹œì§€: ë ˆì‹œí”¼ JSON ìˆ˜ì‹ 
        init_message = await websocket.receive_text()
        recipe_steps = json.loads(init_message)

        if not isinstance(recipe_steps, list) or not all(isinstance(s, str) for s in recipe_steps):
            raise ValueError("ë ˆì‹œí”¼ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        print("ğŸ“¥ ë ˆì‹œí”¼ ìˆ˜ì‹  ì™„ë£Œ:")
        for i, step in enumerate(recipe_steps, 1):
            print(f"  {i}. {step}")

        await websocket.send_text("ë ˆì‹œí”¼ ìˆ˜ì‹  ì™„ë£Œ")

        # ì²« ë‹¨ê³„ ì „ì†¡
        await websocket.send_text(json.dumps({
            "type": "step",
            "message": recipe_steps[0]
        }))

        step_index = 0
        buffer = bytearray()
        silence_counter = 0
        previous_transcript = ""

        while True:
            data = await websocket.receive_bytes()
            buffer.extend(data)
            audio_chunk = np.frombuffer(data, dtype=np.int16).astype(np.float32)
            energy = np.sqrt(np.mean(audio_chunk ** 2))
            silence_counter = silence_counter + 1 if energy < SILENCE_THRESHOLD else 0

            if silence_counter >= SILENCE_FRAMES or len(buffer) >= BUFFER_SIZE:
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
                    sf.write(tmpfile.name, np.frombuffer(buffer, dtype=np.int16), SAMPLE_RATE)
                    tmp_path = tmpfile.name

                with open(tmp_path, "rb") as f:
                    audio_data = f.read()

                audio = speech.RecognitionAudio(content=audio_data)
                response = client.recognize(config=config, audio=audio)

                if response.results:
                    transcript = response.results[0].alternatives[0].transcript.strip()
                    if transcript and transcript != previous_transcript:
                        print(f"ğŸ“ ì¸ì‹ëœ ë°œí™”: {transcript}")

                        system_prompt = (
                            f"ë„ˆëŠ” ìš”ë¦¬ ë„ìš°ë¯¸ì•¼. ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ë“£ê³  í–‰ë™ì„ [NEXT], [REPLAY], [WAIT] ì¤‘ì—ì„œ ì •í™•í•˜ê²Œ í•˜ë‚˜ë§Œ íŒë‹¨í•´ì¤˜.\n\n"
                            f"[í˜„ì¬ ë‹¨ê³„]: '{recipe_steps[step_index]}'\n\n"
                            f"[í–‰ë™ ê¸°ì¤€]\n"
                            f"- ë‹¤ìŒ í‘œí˜„ì´ ë“¤ì–´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ [NEXT]\n"
                            f"â†’ 'ë‹¤ í–ˆì–´', 'ëë‚¬ì–´', 'ì™„ë£Œ', 'ë‹¤ìŒ ë‹¨ê³„', 'ë„˜ì–´ê°€ì', 'ë‹¤ ë§Œë“¤ì—ˆì–´'\n"
                            f"- ë‹¤ìŒ í‘œí˜„ì´ ë“¤ì–´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ [REPLAY]\n"
                            f"â†’ 'ë­ë¼ê³ ', 'ë‹¤ì‹œ', 'ë‹¤ì‹œ ë§í•´ì¤˜', 'ëª» ë“¤ì—ˆì–´', 'í•œ ë²ˆ ë”'\n"
                            f"- ìœ„ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ [WAIT]\n\n"
                            f"[ì¶œë ¥ í˜•ì‹]\n"
                            f"ë©”ì‹œì§€: (ì‚¬ìš©ìì—ê²Œ ì½ì–´ì¤„ ë§ë§Œ ì¨. ì ˆëŒ€ 'ë©”ì‹œì§€:'ë¥¼ ë‹¤ì‹œ ì“°ì§€ ë§ˆ!)\n"
                            f"í–‰ë™: [NEXT|REPLAY|WAIT]"
                        )

                        messages = [
                            SystemMessage(content=system_prompt),
                            HumanMessage(content=transcript)
                        ]
                        response = llm.invoke(messages)
                        action, message = extract_action_and_message(response.content)

                        print(f"ğŸ¤– LLM ì‘ë‹µ: {message} / í–‰ë™: [{action}]")

                        if action == "REPLAY":
                            await websocket.send_text(json.dumps({
                                "type": "speak",
                                "message": recipe_steps[step_index]
                            }))
                        elif action == "NEXT":
                            step_index += 1
                            if step_index < len(recipe_steps):
                                await websocket.send_text(json.dumps({
                                    "type": "step",
                                    "message": recipe_steps[step_index]
                                }))
                            else:
                                await websocket.send_text(json.dumps({
                                    "type": "end",
                                    "message": "ğŸ‰ ìš”ë¦¬ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!"
                                }))
                                break

                        previous_transcript = transcript

                buffer = bytearray()
                silence_counter = 0

    except Exception as e:
        print(f"â— WebSocket ì„œë²„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        await websocket.close()