import asyncio
import websockets
from google.cloud import speech
import warnings
import tempfile
import soundfile as sf
import numpy as np
import time

warnings.filterwarnings("ignore", category=UserWarning)

SAMPLE_RATE = 48000
BUFFER_SECONDS = 5
BUFFER_SIZE = SAMPLE_RATE * BUFFER_SECONDS
SILENCE_THRESHOLD = 100       # ë¬´ìŒìœ¼ë¡œ ê°„ì£¼í•  ì—ë„ˆì§€ ê¸°ì¤€
SILENCE_FRAMES = 3            # ëª‡ í”„ë ˆì„ ì—°ì† ë¬´ìŒì´ë©´ ë²„í¼ë¥¼ ì „ì†¡í• ì§€

client = speech.SpeechClient()

config = speech.RecognitionConfig(
    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
    sample_rate_hertz=SAMPLE_RATE,
    language_code="ko-KR"
)

async def transcribe_audio(websocket):
    print("âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")
    buffer = bytearray()
    start_time = None
    silence_counter = 0
    previous_transcript = ""

    try:
        async for message in websocket:
            print(f"ğŸ§ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ ! í¬ê¸°: {len(message)} bytes")
            buffer.extend(message)

            if start_time is None:
                start_time = time.time()

            # ğŸ¯ ë¬´ìŒ ì—¬ë¶€ íŒë‹¨
            audio_chunk = np.frombuffer(message, dtype=np.int16).astype(np.float32)
            energy = np.sqrt(np.mean(audio_chunk**2))

            if energy < SILENCE_THRESHOLD:
                silence_counter += 1
                print(f"ğŸ”‡ ë¬´ìŒ ê°ì§€ {silence_counter}/{SILENCE_FRAMES}")
            else:
                silence_counter = 0

            # ë¬´ìŒì´ ì¼ì • ì‹œê°„ ì§€ì†ë˜ë©´ STT ìˆ˜í–‰
            if silence_counter >= SILENCE_FRAMES or (len(buffer) >= BUFFER_SIZE):
                print(f"ğŸš€ STT ì¡°ê±´ ì¶©ì¡± â†’ ë°ì´í„° ëª¨ìŒ ì™„ë£Œ, STT ìš”ì²­ ì‹œì‘")

                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
                    audio_array = np.frombuffer(buffer, dtype=np.int16)
                    sf.write(tmpfile.name, audio_array, SAMPLE_RATE)
                    tmp_path = tmpfile.name

                with open(tmp_path, "rb") as f:
                    audio_data = f.read()

                audio = speech.RecognitionAudio(content=audio_data)
                response = client.recognize(config=config, audio=audio)

                if response.results:
                    transcript = response.results[0].alternatives[0].transcript.strip()
                    if transcript and transcript != previous_transcript:
                        print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {transcript}")
                        await websocket.send(transcript)
                        previous_transcript = transcript
                    else:
                        print("âš ï¸ ì¤‘ë³µ ë˜ëŠ” ë¹ˆ ì¸ì‹ ê²°ê³¼")
                else:
                    print("âš ï¸ ì¸ì‹ ê²°ê³¼ ì—†ìŒ")

                buffer = bytearray()
                start_time = None
                silence_counter = 0

    except websockets.exceptions.ConnectionClosed:
        print("â— í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
    except Exception as e:
        print(f"â— ì„œë²„ ì—ëŸ¬: {e}")

async def main():
    print("ğŸš€ ì„œë²„ ì‹¤í–‰ ì¤‘ (ws://0.0.0.0:8000)")
    async with websockets.serve(transcribe_audio, "0.0.0.0", 8000):
        await asyncio.Future()

if __name__ == "__main__":
    asyncio.run(main())
